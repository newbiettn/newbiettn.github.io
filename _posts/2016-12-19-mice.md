---
title: "Multivariate imputation with mice"
author: "newbiettn"
date: "19 December 2016"
layout: post_rmd
---



This is a research experiment of using `mice` package (Buuren and Groothuis-Oudshoorn, 2011) to impute missing values in multivariate data. Basically, `mice` uses __Fully Conditional Specification (FCS)__ method, whereas _chained equation_ is simply an alias of that term. According to (Liu and De, 2015), FCS is more relaxed than the conventional method Joint Modeling (JM) in terms of specifiying distribution of the missing data.

In this experiment, we will employ an open source dataset __Titanic__ as the sample data to conduct the experiment.

#### 1. Multiple imputation vs Single imputation
Both multiple and single imputation techniques are ones that can be used to replace missing values in the data by plausible values. In single imputation, we substitute the missing values of the data by __a single value__. For example, we can replace missing values of a variable by the most common value, or the _mean/median_ value (in case that variable is continuous). Multiple imputation is different in a sense that missing values are replaced by __multiple plausible values__. Using `mice` package, we can even have multiple version of imputed data by trying to impute the data more than one time.


#### 2. Notation

- $\mathbf{Y_j}$ $(j = 1,..., p)$: one of $p$ incomplete variables.
- The observed and missing parts of $Y_j$ are denoted by $\mathbf{Y_j^{obs}}$ and $\mathbf{Y_j^{mis}}$.
    - $Y^{obs} = (Y^{obs},...,Y^{obs}_p)$: observed data in Y.
    - $Y^{mis} = (Y^{mis},...,Y^{mis}_p)$: missing data in Y.
- $\mathbf{m \ge 1}$: the number of imputation.
- $\mathbf{Q}$: predicted model that would be trained on $Y$.

#### 3. Features
`mice` introduces a _modular approach_ to impute data. The imputation framework offered by `mice` comprises of 3 steps: _imputation_, _analysis_ and _pooling_.

- `mice()` Impute incomplete data, creating imputed versions of the data $Y^{(1)}$, $Y^{(2)}$, ..., $Y^{(m)}$.
- `with()` Estimate the predicted model $Q$ on each imputed dataset $Y^{(i)}$, creating multiple versions of the model, which are $\hat{Q}^{(1)}$, $\hat{Q}^{(2)}$,..., $\hat{Q}^{(m)}$
- `pool`   Pool $\hat{Q}^{(1)}$, $\hat{Q}^{(2)}$,..., $\hat{Q}^{(m)}$ into one estimates $\bar{Q}$

A notable feature of this imputation model is that we use our predicted model of interest $Q$ to analyse the imputed data by ourself. By doing that, we can specifically select the best imputed data that suits our investigation.

#### 4. Experiment
#### 4.1. Missing value inspection
First and foremost, load the package and data. In this experiment, we will use Titanic data free available from Kaggle.


{% highlight r %}
# Load library
library(mice) # Imputation
library(VIM) #aggr, marginplot
library(lattice) #stripplot
# Load data
dt <- read.csv("data/titanic.csv", na.strings = c("NA", ""))
# Inspect the data structure
str(dt, strict.width = "wrap") 
{% endhighlight %}



{% highlight text %}
## 'data.frame':	891 obs. of  12 variables:
## $ PassengerId: int 1 2 3 4 5 6 7 8 9 10 ...
## $ Survived : int 0 1 1 1 0 0 0 0 1 1 ...
## $ Pclass : int 3 1 3 1 3 3 1 3 3 2 ...
## $ Name : Factor w/ 891 levels "Abbing, Mr. Anthony",..: 109 191 358 277 16
##    559 520 629 417 581 ...
## $ Sex : Factor w/ 2 levels "female","male": 2 1 1 1 2 2 2 2 1 1 ...
## $ Age : num 22 38 26 35 35 NA 54 2 27 14 ...
## $ SibSp : int 1 1 0 1 0 0 0 3 0 1 ...
## $ Parch : int 0 0 0 0 0 0 0 1 2 0 ...
## $ Ticket : Factor w/ 681 levels "110152","110413",..: 524 597 670 50 473
##    276 86 396 345 133 ...
## $ Fare : num 7.25 71.28 7.92 53.1 8.05 ...
## $ Cabin : Factor w/ 147 levels "A10","A14","A16",..: NA 82 NA 56 NA NA 130
##    NA NA NA ...
## $ Embarked : Factor w/ 3 levels "C","Q","S": 3 1 3 3 3 2 3 3 3 1 ...
{% endhighlight %}



{% highlight r %}
# Remove unnecessary columns
dt[, c("PassengerId", "Name", "Cabin", "Ticket")] <- NULL
# Summary the data
summary(dt) 
{% endhighlight %}



{% highlight text %}
##     Survived          Pclass          Sex           Age       
##  Min.   :0.0000   Min.   :1.000   female:314   Min.   : 0.42  
##  1st Qu.:0.0000   1st Qu.:2.000   male  :577   1st Qu.:20.12  
##  Median :0.0000   Median :3.000                Median :28.00  
##  Mean   :0.3838   Mean   :2.309                Mean   :29.70  
##  3rd Qu.:1.0000   3rd Qu.:3.000                3rd Qu.:38.00  
##  Max.   :1.0000   Max.   :3.000                Max.   :80.00  
##                                                NA's   :177    
##      SibSp           Parch             Fare        Embarked  
##  Min.   :0.000   Min.   :0.0000   Min.   :  0.00   C   :168  
##  1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:  7.91   Q   : 77  
##  Median :0.000   Median :0.0000   Median : 14.45   S   :644  
##  Mean   :0.523   Mean   :0.3816   Mean   : 32.20   NA's:  2  
##  3rd Qu.:1.000   3rd Qu.:0.0000   3rd Qu.: 31.00             
##  Max.   :8.000   Max.   :6.0000   Max.   :512.33             
## 
{% endhighlight %}



{% highlight r %}
# Fare = 0 doesn't make sense, set 0 values in Fare as missing values
dt$Fare[dt$Fare == 0] <- NA
{% endhighlight %}

Our data contains a lot of missing values. We will use different methods to inspect them. First, we will use `md.pattern` method to inspect missing-data patterns.


{% highlight r %}
md.pattern(dt)
{% endhighlight %}



{% highlight text %}
##     Survived Pclass Sex SibSp Parch Embarked Fare Age    
## 705        1      1   1     1     1        1    1   1   0
## 169        1      1   1     1     1        1    1   0   1
##   7        1      1   1     1     1        1    0   1   1
##   2        1      1   1     1     1        0    1   1   1
##   8        1      1   1     1     1        1    0   0   2
##            0      0   0     0     0        2   15 177 194
{% endhighlight %}

Let's intepret information from the retrieved table. Note that in the table, 0 represents missing in the data. Look at the table by row, the table tells us that we have 705 complete rows, 169 rows where only `Age` is missing, `7` rows where only `Fare` is missing, 2 rows where `Embarked` is missing, and 8 rows where both `Fare` and `Age` are missing. Vertically, the tables tells us that `Embarked` has 2 missing values, `Fare` 15, and `Age` 177. In overall, we have 194 missing values in the data, and 169 + 7 + 2 + 8 = 186 incomplete rows.

Besides `md.pattern`, we can visually inspect missing patterns of the data using the package `VIM`. First, we will use `aggr` to aggregate missing values. 


{% highlight r %}
aggr(dt, col = c("navyblue","red"), sortVars = TRUE, numbers = TRUE)
{% endhighlight %}

![center](/../figs/2016-12-19-mice/unnamed-chunk-3-1.png)

{% highlight text %}
## 
##  Variables sorted by number of missings: 
##  Variable       Count
##       Age 0.198653199
##      Fare 0.016835017
##  Embarked 0.002244669
##  Survived 0.000000000
##    Pclass 0.000000000
##       Sex 0.000000000
##     SibSp 0.000000000
##     Parch 0.000000000
{% endhighlight %}

The method `aggr` is essentially similar to `md.patterns`, except that `aggr` displays missing values in portion. For example, roughly 20% (177 rows) of `Age` are incomplete, 1.6% (15 rows) of `Fare` missing, and 0.2% (2 rows) of `Embarked` missing. There are roughly 0.9% (8 rows) of the data where both `Age` and `Fare` are missing. Thus, it seems more convenient when combine both `md.pattern` and `aggr` together to inspect missing values of the data.

We can also observe missing values by pair. The function `marginplot` is perfect for this purpose. We will use `marginplot` to inspect missing patterns of the pair `Age` and `Fare`.


{% highlight r %}
marginplot(dt[, c("Fare", "Age")], col = c("navyblue", "red"), 
           numbers = TRUE, pch = 19)
{% endhighlight %}

![center](/../figs/2016-12-19-mice/unnamed-chunk-4-1.png)

Let's intepret information given by the plot. 

- Blue points in the main area indicates the number of rows that both `Age` and `Fare` are complete. The red points in the left side indicates missing values of `Fare` when `Age` is observed. Similarly, the red points in the bottom margin indicates missing values of `Age` when `Fare` is observed. 
- Three numbers tells us that there are 15 missing values in `Fare` when `Age` is observed, 177 missing values in `Age` when `Fare` is observed, and 8 commonly missing values for both.
- The blue and red boxplots summarise the marginal distribution of complete and incomplete rows. For example, the distribution of complete `Age` values is (0, 80) years old, the distribution of missing value in `Fare` when `Age` is observed is from (20, 50) years old (i.e., 15 passengers who has missing values of `Fare` are from 20 to 50 years old).

##### 4.2. Data imputation with `mice()`
We can simply impute the data by using the function `mice()`. For example,


{% highlight r %}
# Impute missing values
imp <- mice(dt, maxit = 20) 
{% endhighlight %}

By default, `mice()` will create __5 version of imputed data__ (i.e., `m = 5`), and for each version, the default number of iterations is also 5 (i.e., `maxit = 5`). According to the authors, the convergence of Gibbs sampling often happens when `maxit` is between 10 and 20. 


{% highlight r %}
# Extract the 1st version of the imputed data using complete()
dt_imp_1 <- complete(imp, 1)
summary(dt_imp_1)
{% endhighlight %}



{% highlight text %}
##     Survived          Pclass          Sex           Age       
##  Min.   :0.0000   Min.   :1.000   female:314   Min.   : 0.42  
##  1st Qu.:0.0000   1st Qu.:2.000   male  :577   1st Qu.:20.00  
##  Median :0.0000   Median :3.000                Median :28.00  
##  Mean   :0.3838   Mean   :2.309                Mean   :29.47  
##  3rd Qu.:1.0000   3rd Qu.:3.000                3rd Qu.:38.00  
##  Max.   :1.0000   Max.   :3.000                Max.   :80.00  
##      SibSp           Parch             Fare         Embarked
##  Min.   :0.000   Min.   :0.0000   Min.   :  4.013   C:169   
##  1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:  7.925   Q: 77   
##  Median :0.000   Median :0.0000   Median : 14.500   S:645   
##  Mean   :0.523   Mean   :0.3816   Mean   : 32.565           
##  3rd Qu.:1.000   3rd Qu.:0.0000   3rd Qu.: 31.275           
##  Max.   :8.000   Max.   :6.0000   Max.   :512.329
{% endhighlight %}
We can see that missing values no longer exist in the data. Let's see how the data is imputed across 5 versions. First begin with `Embarked`


{% highlight r %}
# Embarked
idx <- which(is.na(dt$Embarked)) # get index of missing values in the original data
sapply(c(1:5), function(x) {(complete(imp, x)$Embarked[idx])})
{% endhighlight %}



{% highlight text %}
##      [,1] [,2] [,3] [,4] [,5]
## [1,] "S"  "S"  "C"  "C"  "C" 
## [2,] "C"  "C"  "C"  "S"  "S"
{% endhighlight %}

So, `mice()` imputed missing values in `Embarked` with different values. Note that in the original data, there are 644 rows of `S`. So I suspect the imputed values are likely (S,S).

Next, we will explore the distribution of imputed values of `Age` and `Fare`. It can be seen from both plots that the distribution of imputed values are similar to that of observed values. 


{% highlight r %}
# Age
dt_imp_1 <- complete(imp, "long", inc = TRUE)
col <- rep(c("blue", "red")[1+as.numeric(is.na(imp$data$Age))], 6)
stripplot(Age~.imp, data = dt_imp_1, jit = TRUE, fac = 0.8, col = col, 
          xlab = "Imputation Number")
{% endhighlight %}

![center](/../figs/2016-12-19-mice/unnamed-chunk-8-1.png)

{% highlight r %}
# Fare
col <- rep(c("blue", "red")[1+as.numeric(is.na(imp$data$Fare))], 6)
stripplot(Fare~.imp, data = dt_imp_1, jit = TRUE, fac = 0.8, col = col, 
          xlab = "Imputation Number")
{% endhighlight %}

![center](/../figs/2016-12-19-mice/unnamed-chunk-8-2.png)

##### 4.2. Data analysis with `with()` 
After imputation, we will analyse imputed data using `with()`. As said, we analyse the imputed data by our predict model of interest $Q$.


{% highlight r %}
fit <- with(imp, glm(Survived ~ Sex + Age + Fare + Pclass + SibSp + Parch 
                     + Embarked, family = "binomial"))
{% endhighlight %}

##### 4.3. Result pooling with `pool()`


{% highlight r %}
pool(fit)
{% endhighlight %}



{% highlight text %}
## Call: pool(object = fit)
## 
## Pooled coefficients:
##  (Intercept)         Sex2          Age         Fare       Pclass 
##  5.612367954 -2.715672626 -0.041810051  0.001051275 -1.218521032 
##        SibSp        Parch    Embarked2    Embarked3 
## -0.375424883 -0.067833252 -0.156404751 -0.400838761 
## 
## Fraction of information about the coefficients missing due to nonresponse: 
## (Intercept)        Sex2         Age        Fare      Pclass       SibSp 
## 0.315568552 0.032948448 0.560292086 0.020903575 0.161178463 0.086276700 
##       Parch   Embarked2   Embarked3 
## 0.006343295 0.110140599 0.046603704
{% endhighlight %}



{% highlight r %}
summary(pool(fit))
{% endhighlight %}



{% highlight text %}
##                      est          se           t        df     Pr(>|t|)
## (Intercept)  5.612367954 0.678209454   8.2752724  45.35872 1.295235e-10
## Sex2        -2.715672626 0.205651025 -13.2052472 714.04960 0.000000e+00
## Age         -0.041810051 0.010374234  -4.0301821  15.10016 1.076977e-03
## Fare         0.001051275 0.002348879   0.4475645 804.47337 6.545880e-01
## Pclass      -1.218521032 0.163161150  -7.4682057 144.23040 7.119638e-12
## SibSp       -0.375424883 0.114396426  -3.2817886 347.45022 1.136168e-03
## Parch       -0.067833252 0.119622057  -0.5670631 873.25534 5.708171e-01
## Embarked2   -0.156404751 0.412503739  -0.3791596 254.55439 7.048854e-01
## Embarked3   -0.400838761 0.242336640  -1.6540576 602.47828 9.863668e-02
##                   lo 95        hi 95 nmis         fmi      lambda
## (Intercept)  4.24668210  6.978053810   NA 0.315568552 0.286040927
## Sex2        -3.11942560 -2.311919654   NA 0.032948448 0.030243597
## Age         -0.06390944 -0.019710663  177 0.560292086 0.505670536
## Fare        -0.00355938  0.005661929   15 0.020903575 0.018472467
## Pclass      -1.54101693 -0.896025136    0 0.161178463 0.149626866
## SibSp       -0.60042150 -0.150428266    0 0.086276700 0.081032202
## Parch       -0.30261358  0.166947078    0 0.006343295 0.004070145
## Embarked2   -0.96875950  0.655950003   NA 0.110140599 0.103176450
## Embarked3   -0.87676594  0.075088420   NA 0.046603704 0.043444033
{% endhighlight %}

#### 5. Convergence assessment
Convergence assessment of Gibbs sampling algorithm is important to check that if the algorithm is converged. According to the paper: _"There is no clear-cut method for determining whether the Gibbs sampling algorithm has converged. What is often done is to plot one or more parameters against the iteration number"_ and _"on convergence, the different streams should be freely intermingled with each other, without showing any definite trends. Convergence is diagnosed when the variance between different sequences is no larger than the variance with each individual sequence"_.


{% highlight r %}
plot(imp)
{% endhighlight %}

![center](/../figs/2016-12-19-mice/unnamed-chunk-11-1.png)

#### 6. Conclusion and discussion



#### References

Buuren, S. & Groothuis-Oudshoorn, K. (2011, December). MICE: Mulitivariate Imputation by Chained Equations in R. Journal of Statistical Software, 45(3), 1–67. Retrieved from http://doc.utwente.nl/78938/

Liu, Y. & De, A. (2015, July). Multiple Imputation by Fully Conditional Spe- cification for Dealing with Missing Data in a Large Epidemiologic Study. International Journal of Statistics in Medical Research, 4(3), 287–295. doi:10.6000/1929-6029.2015.04.03.7
